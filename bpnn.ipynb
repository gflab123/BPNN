{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Defining class for BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    def __init__(\n",
    "        self,hidden_layer_sizes,\n",
    "        l_rate=.001,\n",
    "        n_epoch=20,\n",
    "        batch_size=20,\n",
    "        random_state=0\n",
    "    ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.l_rate= float(l_rate)\n",
    "        self.n_epoch = int(n_epoch)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        self.n = len(hidden_layer_sizes)+1\n",
    "        self.outputs = [None]*(self.n+1)\n",
    "        self.delta = [None]*self.n\n",
    "        \n",
    "        \n",
    "    def activation(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def d_activation(self,x):\n",
    "         return x * (1 - x)\n",
    "    \n",
    "    def pad_ones(X):\n",
    "        pad_width = [(1,0),(0,0)]\n",
    "        return np.pad(X,pad_width=pad_width,constant_values=1)\n",
    "    \n",
    "    def inputs(self,i):\n",
    "        return BPNN.pad_ones(self.outputs[i-1])\n",
    "    \n",
    "    def initialize_random_weights(self):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights = [\n",
    "            np.random.standard_normal((o,i+1))*.001\n",
    "            for i,o in zip(\n",
    "                [self.n_inputs]+self.hidden_layer_sizes,\n",
    "                self.hidden_layer_sizes+[self.n_outputs]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def forward_propagate(self, inputs):\n",
    "        assert (self.weights is not None),\"weights not given\"\n",
    "        self.outputs[-1] = inputs\n",
    "        for i in range(self.n):\n",
    "            self.outputs[i] = self.activation(\n",
    "                self.weights[i] @ self.inputs(i)\n",
    "            )\n",
    "        return self.outputs[self.n-1]\n",
    "    \n",
    "    def backward_propagate_error(self, target):\n",
    "        for i in range(self.n-1, -1, -1):\n",
    "            if i == self.n-1:\n",
    "                errors = self.outputs[i] - target\n",
    "            else:\n",
    "                errors = self.weights[i+1][:,1:].T @ self.delta[i+1] \n",
    "            self.delta[i] = errors * self.d_activation(self.outputs[i])\n",
    "\n",
    "    def update_weights(self):\n",
    "        for i in range(self.n):\n",
    "            self.weights[i] -= self.l_rate * self.delta[i] @ self.inputs(i).T/self.batch_size\n",
    "        \n",
    "    def error(self,actual,predicted):\n",
    "        error = actual-predicted\n",
    "        return np.sum(error * error)\n",
    "    \n",
    "    def fit(self, X_train,y_train,verbose=False):\n",
    "        m = X_train.shape[0]\n",
    "        input_matrix = X_train.T\n",
    "        classes = np.unique(y_train)\n",
    "        target_matrix = (y_train.reshape(-1,1) == classes).T\n",
    "        self.n_inputs = input_matrix.shape[0]\n",
    "        self.n_outputs = target_matrix.shape[0]\n",
    "        self.initialize_random_weights()\n",
    "        if verbose:\n",
    "            print(\"Initial Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            print(\"Training:\")\n",
    "            \n",
    "        for epoch in range(self.n_epoch):\n",
    "            sum_error = 0\n",
    "            fs = range(m+self.batch_size)\n",
    "            for f,t in zip(fs,fs[1:]):\n",
    "                outputs = self.forward_propagate(input_matrix[:,f:t])\n",
    "                sum_error += self.error(target_matrix[:,f:t],outputs)\n",
    "                self.backward_propagate_error(target_matrix[:,f:t])\n",
    "                self.update_weights()\n",
    "            if verbose:\n",
    "                print(f'> epoch={epoch+1}, lrate={self.l_rate:.3}, error={sum_error/m:.5f}')\n",
    "        if verbose:\n",
    "            print(\"Trained Weights:\")\n",
    "            print(*self.weights,sep=\"\\n\")\n",
    "            \n",
    "    def predict(self, inputs):\n",
    "        outputs = self.forward_propagate(inputs.T).T.argmax(axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def accuracy(self,X_test,y_test):\n",
    "        return (self.predict(X_test)==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Loading and processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\"datasets/titanic_processed.csv\")\n",
    "X = titanic_df.drop('Survived',axis = 1).values\n",
    "y = titanic_df['Survived'].values\n",
    "split_ratio = 0.8\n",
    "s = int(split_ratio*X.shape[0])\n",
    "X_train, X_test = X[:s],X[s:]\n",
    "y_train, y_test = y[:s],y[s:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Implementing BPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "[[ 1.33158650e-03  7.15278974e-04 -1.54540029e-03 -8.38384993e-06\n",
      "   6.21335974e-04 -7.20085561e-04  2.65511586e-04  1.08548526e-04\n",
      "   4.29143093e-06 -1.74600211e-04]\n",
      " [ 4.33026190e-04  1.20303737e-03 -9.65065671e-04  1.02827408e-03\n",
      "   2.28630130e-04  4.45137613e-04 -1.13660221e-03  1.35136878e-04\n",
      "   1.48453700e-03 -1.07980489e-03]\n",
      " [-1.97772828e-03 -1.74337230e-03  2.66070164e-04  2.38496733e-03\n",
      "   1.12369125e-03  1.67262221e-03  9.91492158e-05  1.39799638e-03\n",
      "  -2.71247988e-04  6.13204185e-04]\n",
      " [-2.67317189e-04 -5.49309014e-04  1.32708296e-04 -4.76142015e-04\n",
      "   1.30847308e-03  1.95013279e-04  4.00209988e-04 -3.37632337e-04\n",
      "   1.25647226e-03 -7.31969502e-04]\n",
      " [ 6.60231551e-04 -3.50871891e-04 -9.39433360e-04 -4.89337217e-04\n",
      "  -8.04591142e-04 -2.12697639e-04 -3.39140246e-04  3.12169936e-04\n",
      "   5.65152670e-04 -1.47420258e-04]]\n",
      "[[-2.59053368e-05  2.89094204e-04 -5.39879071e-04  7.08160020e-04\n",
      "   8.42224738e-04  2.03580797e-04]\n",
      " [ 2.39470366e-03  9.17458938e-04 -1.12272471e-04 -3.62180447e-04\n",
      "  -2.32182256e-04 -5.01728900e-04]\n",
      " [ 1.12878515e-03 -6.97810030e-04 -8.11221838e-05 -5.29296081e-04\n",
      "   1.04618286e-03 -1.41855603e-03]]\n",
      "[[-0.0003625  -0.00012191  0.00031936  0.0004609 ]\n",
      " [-0.00021579  0.00098907  0.00031475  0.00246765]]\n",
      "Training:\n",
      "> epoch=1, lrate=30.0, error=0.49515\n",
      "> epoch=2, lrate=30.0, error=0.49066\n",
      "> epoch=3, lrate=30.0, error=0.44759\n",
      "> epoch=4, lrate=30.0, error=0.32836\n",
      "> epoch=5, lrate=30.0, error=0.32012\n",
      "> epoch=6, lrate=30.0, error=0.31767\n",
      "> epoch=7, lrate=30.0, error=0.31607\n",
      "> epoch=8, lrate=30.0, error=0.31484\n",
      "> epoch=9, lrate=30.0, error=0.31382\n",
      "> epoch=10, lrate=30.0, error=0.31292\n",
      "> epoch=11, lrate=30.0, error=0.31207\n",
      "> epoch=12, lrate=30.0, error=0.31125\n",
      "> epoch=13, lrate=30.0, error=0.31043\n",
      "> epoch=14, lrate=30.0, error=0.30963\n",
      "> epoch=15, lrate=30.0, error=0.30886\n",
      "> epoch=16, lrate=30.0, error=0.30816\n",
      "> epoch=17, lrate=30.0, error=0.30752\n",
      "> epoch=18, lrate=30.0, error=0.30695\n",
      "> epoch=19, lrate=30.0, error=0.30645\n",
      "> epoch=20, lrate=30.0, error=0.30598\n",
      "Trained Weights:\n",
      "[[ 2.4976328  -3.27137878 -1.35600823  0.52673885  0.52304233 -3.19704645\n",
      "   0.39883285 -0.40978078 -0.51246783 -3.54894486]\n",
      " [ 2.49858236 -3.27054553 -1.35717467  0.52721097  0.5224186  -3.19489909\n",
      "   0.39699621 -0.40938148 -0.51440629 -3.54895058]\n",
      " [ 2.50036793 -3.27256362 -1.36248268  0.52726938  0.51917641 -3.17240322\n",
      "   0.39203713 -0.40863187 -0.52741317 -3.5374918 ]\n",
      " [ 2.49684424 -3.26991156 -1.35703243  0.52480005  0.52215121 -3.1869823\n",
      "   0.39638606 -0.41104905 -0.51872859 -3.54117576]\n",
      " [ 2.49974609 -3.27394878 -1.35582883  0.52807662  0.52134853 -3.19668184\n",
      "   0.39856944 -0.4084107  -0.51188295 -3.55207963]]\n",
      "[[ 0.97395648 -2.1637305  -2.16450945 -2.15728669 -2.15967589 -2.16477422]\n",
      " [ 1.70663229 -2.05598908 -2.05676708 -2.04797014 -2.05198676 -2.05873351]\n",
      " [ 1.40632024 -2.09847304 -2.09768519 -2.09035198 -2.09225785 -2.1003679 ]]\n",
      "[[-2.60724793  1.55437491  1.68003918  1.61398662]\n",
      " [ 2.60724975 -1.55498627 -1.68088901 -1.61254007]]\n",
      "Evaluation:\n",
      "Acuracy of the classifier: 85.96%\n"
     ]
    }
   ],
   "source": [
    "b = BPNN(\n",
    "    hidden_layer_sizes = [5,3],\n",
    "    l_rate=30, n_epoch=20, batch_size=25,random_state=10\n",
    ")\n",
    "b.fit(X_train,y_train,verbose=True)\n",
    "print(\"Evaluation:\")\n",
    "print(f\"Acuracy of the classifier: {b.accuracy(X_test,y_test)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7023248c40563a766f3ae9a0fc81476c1e46277ee22e162240a9cb41b674a272"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
